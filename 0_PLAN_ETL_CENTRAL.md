#  0_PLAN_ETL_CENTRAL.md

---

##  Objetivo General
Centralizar el procesamiento de datos crudos de Spider y GOSOM, consolid谩ndolos en un "CSV Madre" (conceptual, en memoria/descargable) y generando chunks si es necesario, utilizando una aplicaci贸n Next.js/React. Se contempla la futura carga a PostgreSQL.

---

## О M贸dulos y Tareas a Desarrollar (Adaptado a Next.js/React)

### 1. **L贸gica Central (TypeScript en `src/app/(components)/data-refinery/`, `src/lib/etl-logic.ts` o Genkit Flows)**
- [ ] **Consolidaci贸n de Datos (`consolidateData`)**
  - [ ] Parsear CSVs de Spider y Gosom (usar una librer铆a como PapaParse).
  - [ ] L贸gica de merge de datos.
  - [ ] Manejar campos diferentes entre Spider y Gosom (ej: `url` vs `website`), priorizando Gosom en conflictos seg煤n `etl_params.json`.
  - [ ] Implementar deduplicaci贸n real (basado en `deduplication_keys` de `etl_params.json`).
  - _Actual: Simulado en `ConsolidateTabContent.tsx`._
- [ ] **Generaci贸n de Chunks (`generateChunks`)**
  - [ ] Dividir datos consolidados seg煤n `chunkSize`.
  - [ ] Preparar cada chunk para descarga como CSV.
  - _Actual: Simulado en `ChunkingTabContent.tsx`._
- [ ] **Registro de Logs**
  - [x] Implementado mediante `addLog` prop en `page.tsx` y mostrado en `LogsTabContent.tsx`.
  - _Futuro: Si se usa backend/Genkit, considerar logging estructurado all铆._

### 2. **Interfaz de Procesamiento (`src/app/page.tsx` y componentes asociados en `src/app/(components)/data-refinery/`)**
- [x] **Sidebar:**
  - [x] `Input` (ShadCN) para `chunkSize` (controlado en `page.tsx`, con min/max de `etl_params.json`).
- [x] **rea Principal con Pesta帽as (ShadCN `Tabs`):**
  - [x] **Cargar CSVs (`UploadTabContent.tsx`):**
    - [x] Inputs de carga de archivos separados para Spider y Gosom.
    - [ ] Validaci贸n real de campos requeridos (definidos en `upload_validation` de `etl_params.json`) al cargar. _Actual: Validaci贸n de tipo .csv simulada._
  - [x] **Consolidar (`ConsolidateTabContent.tsx`):**
    - [x] Bot贸n para iniciar la consolidaci贸n.
    - [ ] Mostrar datos consolidados reales (post-procesamiento). _Actual: Muestra datos simulados._
    - [ ] Permitir descarga del CSV Madre consolidado.
  - [x] **Chunkear (`ChunkingTabContent.tsx`):**
    - [x] Bot贸n para generar chunks.
    - [ ] Usar datos consolidados reales.
    - [x] Mostrar lista de chunks reales generados para descarga. _Actual: Simulado._
  - [x] **Logs (`LogsTabContent.tsx`):**
    - [x] Muestra logs de la UI y operaciones simuladas.

### 3. **Configuraci贸n y Datos (Client-Side / Conceptual)**
- [x] `config/etl_params.json`:
    - [x] `chunk_size_default`, `chunk_size_min`, `chunk_size_max`.
    - [x] `upload_validation` (campos requeridos para Spider/Gosom).
    - [x] `deduplication_keys`.
    - [x] `conflict_resolution_priority_source`.
    - [x] `postgresql_config_placeholder`.
    - [x] `log_file_path_conceptual` (aclarando que los logs son en UI para la app cliente).
- **Archivos de Datos (Manejo en el Navegador):**
  - **CSVs Crudos (Spider/Gosom):** Cargados por el usuario v铆a `<input type="file">`, procesados en memoria. No se guardan en `data/raw/` en el cliente.
  - **CSV Madre (Consolidado):** Estado en la aplicaci贸n React (`consolidatedData` en `page.tsx`), descargable. No se guarda en `data/consolidated/` en el cliente.
  - **Chunks Generados:** Objetos en memoria, descargables individualmente. No se guardan en `data/chunks/` en el cliente.
  - **Logs de Ejecuci贸n:** Array en el estado de la app (`logs` en `page.tsx`), mostrados en la UI. No se escribe a `data/logs/etl_central.log` en el cliente.

### 4. **Pruebas & CI/CD (Potencial Futuro)**
- [ ] Pruebas unitarias/integraci贸n para l贸gica de transformaci贸n (usando Jest/React Testing Library para funciones en `src/lib/etl-logic.ts` u equivalentes).
- [ ] GitHub Actions: configurar para ejecutar pruebas automatizadas.

---

##  Historial de Mejoras (Checklist Estilo GOSOM - Adaptado)
- **Fase 1: MVP (Actual - Funcionalidad Simulada)**
  - [x] Interfaz b谩sica con carga de archivos (validaci贸n de tipo de archivo).
  - [x] Consolidaci贸n simulada, deduplicaci贸n simulada, chunking simulado.
  - [x] Interfaz completamente funcional con Next.js/React y ShadCN UI.
  - [x] Configuraci贸n y uso b谩sico de `etl_params.json` para `chunkSize`.
  - [x] Sistema de logging en la UI.
- **Fase 2: Implementaci贸n de L贸gica Real de ETL (Client-Side)**
  - [ ] Implementar parseo real de CSV (ej: PapaParse) en `UploadTabContent.tsx` o `src/lib/etl-logic.ts`.
  - [ ] Implementar validaci贸n de encabezados CSV seg煤n `etl_params.json` en `UploadTabContent.tsx`.
  - [ ] Implementar consolidaci贸n real con manejo de conflictos y deduplicaci贸n en `src/lib/etl-logic.ts` e integrarlo en `ConsolidateTabContent.tsx`.
  - [ ] Implementar chunking real en `src/lib/etl-logic.ts` e integrarlo en `ChunkingTabContent.tsx`.
  - [ ] Mejorar manejo de errores y feedback al usuario en todas las pesta帽as.
  - [ ] Asegurar que la descarga de CSVs (consolidado y chunks) funcione con datos reales.
- **Fase 3: Integraci贸n con Backend (Potencial - Genkit/PostgreSQL)**
  - [ ] Identificar operaciones que se beneficiar铆an de un backend (ej: procesamiento de archivos muy grandes, persistencia).
  - [ ] Desarrollar Genkit flows para dichas operaciones si es necesario.
  - [ ] Implementar carga a base de datos PostgreSQL (requiere Genkit flow o API de backend, usando `postgresql_config_placeholder` de `etl_params.json`).
- **Fase 4: Automatizaci贸n (Requerir铆a Backend/Servicios Cloud)**
  - [ ] Considerar ejecuci贸n autom谩tica/programada si se migra a una arquitectura con backend.

---

##  Siguientes Pasos Inmediatos (Basado en el estado actual y Fase 2)
1. **Validar este `0_PLAN_ETL_CENTRAL.md` actualizado.** (Iteraci贸n actual).
2. **Implementar parseo y validaci贸n de CSVs en `UploadTabContent.tsx`:**
    - Utilizar una librer铆a como PapaParse para leer el contenido de los archivos CSV.
    - Leer `upload_validation` de `config/etl_params.json`.
    - Validar que los encabezados requeridos existan en los respectivos archivos.
    - Mostrar errores espec铆ficos al usuario en la UI (`toast` y/o mensajes en la Card) si la validaci贸n falla.
    - Si la validaci贸n es exitosa, almacenar los datos parseados (array de objetos) en el estado (`spiderFileData`, `gosomFileData`) en lugar de solo el objeto `File`.
3. **Implementar la l贸gica real de consolidaci贸n y deduplicaci贸n:**
    - Crear/Usar un archivo para la l贸gica, ej: `src/lib/etl-logic.ts`.
    - Crear funciones como:
        - `function consolidateAndDeduplicate(spiderData: Record<string, string>[], gosomData: Record<string, string>[], deduplicationKeys: string[], prioritySource: string, gosomFields: string[], spiderFields: string[]): ConsolidatedData`
    - Esta funci贸n debe:
        - Mapear campos (ej. si Spider usa 'telefono' y Gosom 'tel茅fono', o 'direccion' vs 'address').
        - Unir los dos conjuntos de datos.
        - Aplicar la l贸gica de prioridad de `prioritySource` (Gosom) para campos en com煤n si hay conflicto.
        - Deduplicar basado en `deduplicationKeys`.
    - Integrar esta funci贸n en `ConsolidateTabContent.tsx`, usando los datos parseados del paso anterior y los par谩metros de `etl_params.json`.
    - Actualizar la UI para mostrar los datos consolidados reales y permitir su descarga como CSV.
4. **Implementar la l贸gica real de chunking:**
    - En `src/lib/etl-logic.ts` (o similar), crear funci贸n: `function generateChunks(consolidatedData: ConsolidatedData, chunkSize: number): DataChunk[]`.
    - Integrar en `ChunkingTabContent.tsx`, usando los datos consolidados reales.
    - Asegurar que la descarga de cada chunk funcione correctamente.
5. **Mejorar el feedback visual y manejo de estados (loading, success, error) en todas las pesta帽as durante estas operaciones.**

---
